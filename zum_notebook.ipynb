{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ZUM</center>\n",
    "# <center> Projekt -- dokumentacja końcowa </center>\n",
    "\n",
    "## <center> Jan Budziński </center>\n",
    "## <center> Jarosław Nachyła </center>\n",
    "\n",
    "Temat 14: Nienadzorowana detekcja anomalii na podstawie niepodobieństwa do grup wyznaczanych\n",
    "za pomocą algorytmów grupowania. Implementacja w formie opakowania umożliwiającego użycie różnych\n",
    "algorytmów grupowania dostępnych w środowisku R lub Python i różnych miar niepodobieństwa. Porów-\n",
    "nanie z nienadzorowaną detekcją anomalii za pomocą algorytmów klasyfikacji jednoklasowej dostępnych\n",
    "w środowisku R lub Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Zbiory danych\n",
    "\n",
    "### 1.1 HTTP KDD Cup 99 dataset.\n",
    "\n",
    "Pierwszym zbiorem danych do testowania, który chcemy wykorzystać, jest zbiór zawierający anomalie w ruchu HTTP, znany jako \"HTTP KDD Cup 99 dataset\". Ten zbiór danych jest używany do badania i wykrywania nietypowych zachowań w ruchu sieciowym, co jest kluczowe dla bezpieczeństwa cybernetycznego. Dostępny jest pod adresem [https://odds.cs.stonybrook.edu/http-kddcup99-dataset/](https://odds.cs.stonybrook.edu/http-kddcup99-dataset/)\n",
    "\n",
    "| Liczba przykładów | Atryb. dyskret. | Atryb. rzecz. | Brak. atryb. | Liczba klas |\n",
    "|-------------------|-----------------|---------------|--------------|-------------|\n",
    "| 567479            | 0               | 3             | 0            | 1           |\n",
    "\n",
    "Table 1: Podsumowanie zbioru http.\n",
    "\n",
    "Wszystkie 3 atrybuty zbioru są wartościami rzeczywistymi. Zbiór nie jest wstępnie podzielony na dane treningowe i testowe.\n",
    "Dystrybucja klas w zbiorze: anomalii (ang. outlier) i wartości poprawnych (ang. inlier):\n",
    "\n",
    "| Class  | N      | N[%] |\n",
    "|--------|--------|------|\n",
    "| inlier | 565268 | 99.6%|\n",
    "| outlier| 2211   | 0.4% |\n",
    "\n",
    "Jak widać klasy są bardzo niezbalansowane, ilość anomalii to zaledwie 0.4 procenta. Jest to duża dysproporcja, ale jest to dość popularne w tego typu zbiorach.\n",
    "\n",
    "### 1.2 Statlog Shuttle dataset.\n",
    "\n",
    "Zbiór danych \"Shuttle\" (często nazywany także \"Statlog Shuttle Dataset\") to zbiór używany w analizie danych i uczeniu maszynowym, który zawiera informacje na temat symulatora promu kosmicznego. Dostępny jest pod linkiem [https://odds.cs.stonybrook.edu/shuttle-dataset/](https://odds.cs.stonybrook.edu/shuttle-dataset/).\n",
    "\n",
    "| Liczba przykładów | Atryb. dyskret. | Atryb. rzecz. | Brak. atryb. | Liczba klas |\n",
    "|-------------------|-----------------|---------------|--------------|-------------|\n",
    "| 49097             | 0               | 9             | 0            | 1           |\n",
    "\n",
    "Table 2: Podsumowanie zbioru shuttle.\n",
    "\n",
    "Wszystkie 9 atrybutów zbioru są wartościami rzeczywistymi. Zbiór nie jest wstępnie podzielony na dane treningowe i testowe.\n",
    "Dystrybucja klas w zbiorze: anomalii (ang. outlier) i wartości poprawnych (ang. inlier):\n",
    "\n",
    "| Class  | N      | N[%] |\n",
    "|--------|--------|------|\n",
    "| inlier | 45586  | 93%  |\n",
    "| outlier| 3511   | 7%   |\n",
    "\n",
    "Ilość anomalii jest dziesięciokrotnie większa niż dla zbioru poprzedniego. Został wybrany w celach porównawczych.\n",
    "\n",
    "## 2. Założenia dla algorytmów grupowania i klasyfikacji jednoklasowej.\n",
    "\n",
    "### 2.1 Trenowanie i ewaluacja na zbiorze treningowym dla algorytmów grupowania.\n",
    "\n",
    "W eksperymentach nie korzystano z metody `predict`, ponieważ metoda ta wymaga centrów klastrów, które są dostępne tylko w przypadku algorytmu KMeans korzystającego z API. W przypadku DBSCAN wyliczenie centrów z danych może być błędem, ponieważ klastry mogą nie być wypukłe, co może prowadzić do sytuacji, w której centrum klastrów znajduje się w innym klastrze.\n",
    "\n",
    "### 2.2 Klasyfikacja jednoklasowa - trening\n",
    "\n",
    "W eksperymentach zastosowano algorytmy klasyfikacji jednoklasowej, takie jak One-Class SVM i Isolation Forest, które są przystosowane do detekcji anomalii. Tutaj zastosowano podział na dane treningowe jednak poniewaz mamy doczynienia z modelami jednoklasowymi to uczono model tylko na inlierach natomiast testowano na inlierach i outlierach z zachowaniem proporcji.\n",
    "\n",
    "### 2.3 Algorytmy grupowania metryka AUC PR.\n",
    "\n",
    "Algorytmy grupowania nie  posiadaja funkcji predict proba, w celu obliczenia tej metryki zastosowano przekształcenie dystansu punktów od centrów klastrów. Nie można jednak tego porównywac z implementacją predict proba w modelach klasyfikacji takich jak regresja logistyczna. Wyniki uzyskane w ten sposób musza podlegać krytycznej analizie. Jedynie dla KMeans można uznać, że wyniki są w 100% miarodajne, poniewaz centra klastrów są dostępne natywnie poprzez API metody.\n",
    "\n",
    "\n",
    "## 2. Implementacja\n",
    "\n",
    "### 2.1. Nienadzorowana detekcja anomalii\n",
    "\n",
    "W ramach projektu zaimplementowano klasę <i>AnomalyDetector</i>, będącą opakowaniem na algorytmy grupowania KMeans, DBSCAN oraz AgglomerativeClustering, jak również na miary niepodobieństwa euklidesową, Mahalanobisa i Manhattan. Celem tejże klasy jest stworzenie łatwego w obsłudze środowiska testowego, które w miarę możliwości (niektóre algorytmy różnią się wejściami) będzie jednorodne w użyciu dla każdego z porównywanych algorytmów i miar.\n",
    "Klasa ta zawiera następujące metody:\n",
    "\n",
    "- fit -- dopasowuje model do danych wejściowych,\n",
    "- fit_predict -- wykonuje trening modelu i jednocześnie przewidująca klasy i określająca dystanse od centrów klastrów dla danych wejściowych,\n",
    "- transform_distances -- określa, czy dane wejściowe są anomaliami na podstawie dystansu otrzymanego z wybranej miary niepodobieństwa,\n",
    "- transform_labels -- dla liczby klastrów większych niż 2, metoda ta zmienia przypisanie do wszystkich klastrów poza najliczniejszym w anomalię.\n",
    "\n",
    "\n",
    "Dzięki tym metodom użytkownik jest w stanie w łatwy sposób testować różne modele i miary niepodobieństwa, zmieniając wyłącznie jeden parametr w kodzie.\n",
    "\n",
    "Kod implementujący tę klasę jest w pliku anomaly_detector.py.\n",
    "\n",
    "Ponadto utworzono klasę _AnomalyDetectorEvaluator_ zawierającą metody obliczające metryk potrzebnych do ewaluacji wytrenowanych modeli. \n",
    "\n",
    "Testowane metryki to:\n",
    "\n",
    "- dokładność (accuracy)\n",
    "- precyzja (precision)\n",
    "- czułość (recall)\n",
    "- f1 (F1 Score)\n",
    "- czułość klasy pozytywnej (positive recall)\n",
    "- czułość klasy negatywnej  (negative recall)\n",
    "- precyzja klasy pozytywnej (positive precision)\n",
    "- precyzja klasy negatywnej (negative precision)\n",
    "- pole pod wykresem krzywej precyzji i czułości (AUC PRC)\n",
    "\n",
    "Wszystkie te metryki zostały dokładniej opisane w dokumentacji wstępnej. Jednakże, z uwagi na fakt, iż dane z założenia są wysoce niezbalansowane (jako że są to dane anomalii, to wejścia o pozytywnej klasie stanowią poniżej 1% wszystkich) uznano, że zwykła dokładność może niewiele powiedzieć, jako że przypisanie wszystkim danym klasy negatywnej pozwala osiągnąć powyżej 99% poprawnych predykcji. W tym celu dodano metryki czułości i precyzji dla obu klas. Dodatkowo, z uwagi na fakt, iż dane są niezbalansowane, zdecydowano się na użycie AUC PRC, jako że jest to miara, która nie zależy od proporcji klas.\n",
    "\n",
    "Eksperymenty były zapisywane do plików JSON, a następnie wczytywane do DataFrame'ów w celu analizy wyników. Znajdują sie one w katalogu results.\n",
    "Kod z klasą AnomalyDetectorEvaluator znajduje się w pliku metrics.py.\n",
    "\n",
    "### 2.2. Klasyfikacja jednoklasowa\n",
    "\n",
    "W ramach projektu zaimplementowano klasę <i>OneClassClassifier</i>, będącą opakowaniem na algorytmy klasyfikacji jednoklasowej One-Class SVM oraz Isolation Forest. Implementacja znajduje sie w pliku one_class_classifier.py. Znajduje się tam klasa OneClassAnnomalyDetector. Modele są zaincjalizowane ze deaultowymi parametrami.Celem projektu nie był tuning parametrów modeli, a jedynie porównanie ich wydajności w detekcji anomalii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Porównanie modeli grupowaniaz modelami klasyfikacji jednoklasowej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Opis eksperymentów.\n",
    "\n",
    "Nienadzorowana detekcja anomalii na podstawie niepodobieństwa do grup wyznaczanych za pomocą algorytmów grupowania została przeprowadzona w ramach eksperymentów porównujących algorytmy klasyfikacji jednoklasowej, takie jak One-Class SVM i Isolation Forest, z algorytmami grupowania. Eksperymenty miały na celu zbadanie wydajności tych modeli w kontekście detekcji anomalii.\n",
    "\n",
    "W ramach pierwszego eksperymentu wykonano testy porównawcze iloczynu kartezjańskiego 3 wybranych modeli, 3 miar niepodobieństwa i 2 zbiorów danych, co dało łącznie 18 pojedynczych testów.\n",
    "\n",
    "Podczas przeprowadzania eksperymentu wystąpiły pewne problemy. Mianowicie, algorytm Agglomerative Clustering cechuje się wysokimi złożonościami: złożoność obliczeniowa to \\(O(n^2)\\), a czasowa to \\(O(n^3)\\). Z tego względu trening na całych zbiorach danych, a w szczególności na zbiorze HTTP, był niemożliwy. W związku z tym zastosowano subsampling.\n",
    "\n",
    "\n",
    "### 3.2 Szczegóły Subsampling i Eksperymentów\n",
    "\n",
    "W przeprowadzonych eksperymentach dotyczących nienadzorowanej detekcji anomalii przy użyciu algorytmów grupowania, zastosowano różne techniki subsamplingu w celu obsługi dużych zbiorów danych oraz złożoności obliczeniowej niektórych algorytmów. Poniżej znajduje się szczegółowe wyjaśnienie strategii subsamplingu użytych dla różnych eksperymentów oraz wyjaśnienie, dlaczego niektóre eksperymenty nie zostały wykonane.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Zbiór Danych      | Algorytm                    | Subsampling                           |\n",
    "|-------------------|-----------------------------|---------------------------------------|\n",
    "| HTTP              | Isolation Forest            | 40% zbioru danych             |\n",
    "| HTTP              | One-Class SVM               | 40% zbioru danych              |\n",
    "| HTTP              | DBSCAN                      | 10% zbioru danych               |\n",
    "| HTTP              | Agglomerative Clustering    | 5% zbioru danych                      |\n",
    "\n",
    "Subsampling stosowany był z zachowaniem proporcji klasy mniejszościowej tak aby próba zawierała wszystkie outliery których było odpowiedznio mało\n",
    "około 0.4% dla zbioru HTTP i 7% dla zbioru shuttle. \n",
    "\n",
    "### 3.3 Braki w eksperymentach.\n",
    "\n",
    "DBSCAN z metryką Mahalanobis nie zostały wykonane ze względu na bardzo długie czasy nauki nawet dla małych próbek danych(mozliwy problem w implemntacji w bibliotece).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiments import Experiments\n",
    "\n",
    "# w celu uruchomienia wszystkcich eksperymentów należy odkomentować poniższy kod czas wykonania około 1h\n",
    "exps = Experiments()\n",
    "\n",
    "# exps.run_http_one_class()\n",
    "# exps.run_shuttle_one_class()\n",
    "#\n",
    "# exps.run_http_meta_cost()\n",
    "# exps.run_shuttle_meta_cost()\n",
    "#\n",
    "# exps.run_http_dbscan_experiment()\n",
    "# exps.run_http_kmeans_experiment()\n",
    "# exps.run_http_agglomerative_experiment()\n",
    "#\n",
    "# exps.run_shuttle_dbscan_experiment()\n",
    "# exps.run_shuttle_kmeans_experiment()\n",
    "# exps.run_shuttle_agglomerative_experiment()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Poniżej znajduje się kod, który wczytuje wyniki eksperymentów zapisane w plikach JSON do DataFrame'ów i wyświetla wyniki."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "             model       metric  accuracy  positive_recall  negative_recall  \\\n0  isolationforest          N/A  0.907282         1.000000         0.876376   \n1           dbscan    euclidean  0.993616         1.000000         0.993366   \n2           dbscan    manhattan  0.993616         1.000000         0.993366   \n3              svm          N/A  0.623021         1.000000         0.497362   \n4           kmeans    euclidean  0.566687         0.005427         0.568883   \n5           kmeans    manhattan  0.990925         0.014925         0.994742   \n6           kmeans  mahalanobis  0.567260         0.005427         0.569458   \n7    agglomerative    euclidean  0.994651         0.997286         0.994445   \n8    agglomerative    manhattan  0.994651         0.997286         0.994445   \n9    agglomerative  mahalanobis  0.994651         0.997286         0.994445   \n\n   positive_precision  negative_precision        f1  auc_score  \n0            0.729462            1.000000  0.843571        NaN  \n1            0.854988            1.000000  0.921826   0.035111  \n2            0.854988            1.000000  0.921826   0.035111  \n3            0.398738            1.000000  0.570139        NaN  \n4            0.000049            0.993208  0.000098   0.538963  \n5            0.010982            0.996142  0.012653   0.538963  \n6            0.000049            0.993215  0.000098   0.539007  \n7            0.933531            0.999787  0.964356   0.061553  \n8            0.933531            0.999787  0.964356   0.063167  \n9            0.933531            0.999787  0.964356   0.062629  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>f1</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>isolationforest</td>\n      <td>N/A</td>\n      <td>0.907282</td>\n      <td>1.000000</td>\n      <td>0.876376</td>\n      <td>0.729462</td>\n      <td>1.000000</td>\n      <td>0.843571</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dbscan</td>\n      <td>euclidean</td>\n      <td>0.993616</td>\n      <td>1.000000</td>\n      <td>0.993366</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.921826</td>\n      <td>0.035111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dbscan</td>\n      <td>manhattan</td>\n      <td>0.993616</td>\n      <td>1.000000</td>\n      <td>0.993366</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.921826</td>\n      <td>0.035111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>svm</td>\n      <td>N/A</td>\n      <td>0.623021</td>\n      <td>1.000000</td>\n      <td>0.497362</td>\n      <td>0.398738</td>\n      <td>1.000000</td>\n      <td>0.570139</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kmeans</td>\n      <td>euclidean</td>\n      <td>0.566687</td>\n      <td>0.005427</td>\n      <td>0.568883</td>\n      <td>0.000049</td>\n      <td>0.993208</td>\n      <td>0.000098</td>\n      <td>0.538963</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>kmeans</td>\n      <td>manhattan</td>\n      <td>0.990925</td>\n      <td>0.014925</td>\n      <td>0.994742</td>\n      <td>0.010982</td>\n      <td>0.996142</td>\n      <td>0.012653</td>\n      <td>0.538963</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>kmeans</td>\n      <td>mahalanobis</td>\n      <td>0.567260</td>\n      <td>0.005427</td>\n      <td>0.569458</td>\n      <td>0.000049</td>\n      <td>0.993215</td>\n      <td>0.000098</td>\n      <td>0.539007</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>agglomerative</td>\n      <td>euclidean</td>\n      <td>0.994651</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.964356</td>\n      <td>0.061553</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>agglomerative</td>\n      <td>manhattan</td>\n      <td>0.994651</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.964356</td>\n      <td>0.063167</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>agglomerative</td>\n      <td>mahalanobis</td>\n      <td>0.994651</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.964356</td>\n      <td>0.062629</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "def load_metrics_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "def process_files(directory, pdataset = \"http\", models_excluded = []):\n",
    "    results = []\n",
    "\n",
    "    # Przeglądanie wszystkich plików w katalogu\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # Parsing nazwy pliku\n",
    "            parts = file_name.split('_')\n",
    "            model = parts[0]\n",
    "            dataset = parts[1]\n",
    "\n",
    "            if dataset != pdataset or model in models_excluded:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            metrics_data = load_metrics_from_json(file_path)\n",
    "\n",
    "\n",
    "\n",
    "            if isinstance(metrics_data, dict):  # Dla isolation forest i svm\n",
    "                metric = \"N/A\"\n",
    "                avg_metrics = metrics_data['avg_metrics']\n",
    "                result = {\n",
    "                    'model': model,\n",
    "                    'metric': metric,\n",
    "                    'accuracy': avg_metrics.get('accuracy'),\n",
    "                    'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                    'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                    'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                    'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                    'f1': avg_metrics.get('f1'),\n",
    "                   \n",
    "                    'auc_score': avg_metrics.get('auc_pr')\n",
    "                }\n",
    "                results.append(result)\n",
    "            else:  # Dla pozostałych modeli\n",
    "                for entry in metrics_data:\n",
    "                    metric = entry['metric']\n",
    "                    avg_metrics = entry['avg_metrics']\n",
    "                    result = {\n",
    "                    'model': model,\n",
    "                    'metric': metric,\n",
    "                    'accuracy': avg_metrics.get('accuracy'),\n",
    "                    'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                    'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                    'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                    'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                    'f1': avg_metrics.get('f1'),\n",
    "                    'auc_score': avg_metrics.get('auc_pr')\n",
    "                    }\n",
    "                    results.append(result)\n",
    "\n",
    "    # Tworzenie DataFrame z wynikami\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "pd.set_option('display.max_rows', 50)\n",
    "process_files('./results/', models_excluded=['metacost'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T02:04:01.281731Z",
     "start_time": "2024-06-16T02:04:01.269902Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wyniki dla zbioru HTTP. Analizując metrykę F1 najlepsze wyniki uzyskał model agglomerative clustering, a także DBSCAN, różnice pomiędzy nimi jak i ich wariantami metryk nie są istotne statystycznie. Jednocześnie modele te mają bardzo niską wartość AUC PR. Może to oznaczać, że model jest dobrze skalibrowany dla jednej konkretnej wartości progu, ale jego zdolność do generalizacji i stabilności przy innych progach jest ograniczona. Pamietamy także, że metryki AUC PR są oparte o dystanse od centrów klastrów co niekoniecznie może być miarodajne. Szczególnie jeśli klaster nie jest wypukły jego środek wcale nie jest środkiem wyznaczonych punktów. Widac także, że wyniki dla KMeans jesli chodzi o metryke AUC PR wyglądają bardziej wiarygodnie niż dla pozostałych metod grupowania(dla Kmeans centra klastrów są dostepne natywnie poprzez API metody). Dla modelu kmeans czułość jest bardzo niska co oznacza, że model prawie nie wykrywa outlierów. Jeślichodzi o modele klasyfikacji jednoklasowej do zdecydowanie lepszy wynik uzyskał model Isolation Forest. Być może tuning parametrów mógłby znacznie poprawić wyniki dla modelu One-Class SVM i Isolation forest. Trzy modele uzyskały 100% wynik detekcji anomalii(positive recall), co jest zaskakująco wysoką wartością. Tak więc biorac pod uwagę poprzdnia wartość F1, faworytem staje sie model DbScan z metryką Manhattan."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "             model       metric  accuracy  positive_recall  negative_recall  \\\n0           dbscan    euclidean  0.993971         0.958416         0.996710   \n1           dbscan    manhattan  0.995376         0.982056         0.996402   \n2              svm          N/A  0.621618         0.997152         0.496440   \n3    agglomerative    euclidean  0.995988         0.944745         0.999934   \n4    agglomerative    manhattan  0.995988         0.944745         0.999934   \n5    agglomerative  mahalanobis  0.995988         0.944745         0.999934   \n6           kmeans    euclidean  0.974907         0.690117         0.996841   \n7           kmeans    manhattan  0.974907         0.690117         0.996841   \n8           kmeans  mahalanobis  0.786830         0.017089         0.846115   \n9  isolationforest          N/A  0.884150         0.987183         0.849805   \n\n   positive_precision  negative_precision        f1  auc_score  \n0            0.957326            0.996797  0.957871   0.215972  \n1            0.954596            0.998615  0.968131   0.216555  \n2            0.397615            0.998091  0.568529        NaN  \n3            0.999096            0.995762  0.971161   0.435803  \n4            0.999096            0.995762  0.971161   0.530860  \n5            0.999096            0.995762  0.971161   0.429757  \n6            0.943903            0.976617  0.797302   0.373327  \n7            0.943903            0.976617  0.797302   0.379373  \n8            0.008481            0.917876  0.011336   0.834842  \n9            0.686609            0.994998  0.809908        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>f1</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dbscan</td>\n      <td>euclidean</td>\n      <td>0.993971</td>\n      <td>0.958416</td>\n      <td>0.996710</td>\n      <td>0.957326</td>\n      <td>0.996797</td>\n      <td>0.957871</td>\n      <td>0.215972</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dbscan</td>\n      <td>manhattan</td>\n      <td>0.995376</td>\n      <td>0.982056</td>\n      <td>0.996402</td>\n      <td>0.954596</td>\n      <td>0.998615</td>\n      <td>0.968131</td>\n      <td>0.216555</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>svm</td>\n      <td>N/A</td>\n      <td>0.621618</td>\n      <td>0.997152</td>\n      <td>0.496440</td>\n      <td>0.397615</td>\n      <td>0.998091</td>\n      <td>0.568529</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>agglomerative</td>\n      <td>euclidean</td>\n      <td>0.995988</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.971161</td>\n      <td>0.435803</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>agglomerative</td>\n      <td>manhattan</td>\n      <td>0.995988</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.971161</td>\n      <td>0.530860</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>agglomerative</td>\n      <td>mahalanobis</td>\n      <td>0.995988</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.971161</td>\n      <td>0.429757</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>kmeans</td>\n      <td>euclidean</td>\n      <td>0.974907</td>\n      <td>0.690117</td>\n      <td>0.996841</td>\n      <td>0.943903</td>\n      <td>0.976617</td>\n      <td>0.797302</td>\n      <td>0.373327</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>kmeans</td>\n      <td>manhattan</td>\n      <td>0.974907</td>\n      <td>0.690117</td>\n      <td>0.996841</td>\n      <td>0.943903</td>\n      <td>0.976617</td>\n      <td>0.797302</td>\n      <td>0.379373</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>kmeans</td>\n      <td>mahalanobis</td>\n      <td>0.786830</td>\n      <td>0.017089</td>\n      <td>0.846115</td>\n      <td>0.008481</td>\n      <td>0.917876</td>\n      <td>0.011336</td>\n      <td>0.834842</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>isolationforest</td>\n      <td>N/A</td>\n      <td>0.884150</td>\n      <td>0.987183</td>\n      <td>0.849805</td>\n      <td>0.686609</td>\n      <td>0.994998</td>\n      <td>0.809908</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_files('./results/', models_excluded=['metacost'], pdataset='shuttle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T02:42:45.797271Z",
     "start_time": "2024-06-16T02:42:45.787919Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dla zbioru shuttle sytuacja wygląda analogicznie jak dla zbioru HTTP. Model agglomerative clustering oraz DBSCAN uzyskały najlepsze wyniki dla metryki F1, jednakże ich wyniki dla AUC PR są bardzo niskie, jednak sporo wyższe niz w przypadku zbioru HTTP. W tym eksperymencie znacznie lepiej poradziły sobie modele KMeans. Gdybysmy mieli się skupić na maksymalnej wykrwalności anomalii(Positive Recall) to najlepszym modelem jest One Class SVM(wynik 0.997), potem Isoaltion Forest(0.993). Modele klasyfiakcji jednoklasowej radzą sobie lepiej w tym przypadku niż modele grupowania."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Poprawa wyników algorytmu MetaCost opartego o KMeans, porównanie z algorytmem KMeans.\n",
    "\n",
    "### 4.1 Algorytm MetaCost.\n",
    "\n",
    "### 4. Poprawa wyników algorytmu MetaCost opartego o KMeans, porównanie z algorytmem KMeans.\n",
    "\n",
    "### 4.1 Algorytm MetaCost\n",
    "\n",
    "\n",
    "Algorytm MetaCost jest metodą, która przekształca klasyfikatory uczące się bezpośrednio na danych treningowych w klasyfikatory uwzględniające koszty błędów. Podstawową ideą MetaCost jest przekształcenie problemu klasyfikacji w taki sposób, aby minimalizować oczekiwany koszt błędów. Algorytm ten działa poprzez generowanie wielu próbek z oryginalnego zbioru danych, trenowanie modeli na tych próbkach, a następnie agregowanie wyników, aby uzyskać końcową klasyfikację.\n",
    "\n",
    "Jedynym algorytmem grupowania, który można zastosować w algorytmie MetaCost, jest KMeans. Dlatego że posiada on metrykę odległości,  zbudowana na poprawnie wyznaczonych centrach klastrów.\n",
    "\n",
    "Algorytm jest zaimplementowany w pliku metacost.py. Znajduje sie tam klasa MetaCost która zawiera dokumentację pseudokodu algorytmu.\n",
    "Algorytm został zaimplementowany zgodnie z pracą naukową \"MetaCost: A General Method for Making Classifiers Cost-Sensitive\" autorstwa Pedro Domingosa dostępną pod adresem https://homes.cs.washington.edu/~pedrod/papers/kdd99.pdf).\n",
    "\n",
    "### 4.2 Założenia eksperymentów\n",
    "\n",
    "W orginalnej pulikacji znajdowały sie 2 algorytmy dla macierzy kosztów: Fixed-Interval Cost i Probability-Dependent Cost.\n",
    "Pierwsza generuje macierz kosztów poprzez losowe przypisanie wartości ze stałego zakresu np. od [0, 1000] na przekątnej macierzy(poprawne klasyfukacje) oraz wartości z zakresu np. [0, 10000] dla pozostałych elementów. Celem jest modelowanie kosztów klasyfikacji, gdzie wartości na przekątnej dla błędnych klasyfikacji są statystycznie wyższe.\n",
    "\n",
    "\n",
    "Druga metoda generuje macierz kosztów, biorąc pod uwagę prawdopodobieństwa wystąpienia każdej klasy w zbiorze treningowym. Wartości na przekątnej są losowane z zakresu [0, 1000], natomiast pozostałe elementy są losowane z zakresu np. [0, 2000] przemnożonego przez stosunek prawdopodobieństw klas.\n",
    "\n",
    "Obie metody zostały zaimplementowane w pliku metacost.py, jednak przynosiły bardzo złe rezultaty. W eksperymentach zastosowano macierz kosztów opartą na dysproporcji między klasami (1 + stosunek liczby outlierów do liczby inlierów) dla zbioru HTTP oraz stały koszt równy 10 dla zbioru Shuttle.\n",
    "\n",
    "#### Eksperymenty z MetaCost\n",
    "\n",
    "Eksperymenty zostały przeprowadzone przy użyciu dwóch różnych zbiorów danych: HTTP i Shuttle. \n",
    "\n",
    "\n",
    "#### Uwagi\n",
    "**Wpływ macierzy kosztów:**\n",
    "Algorytm MetaCost jest bardzo wrażliwy na zmiany w macierzy kosztów. Dobre dopasowanie macierzy kosztów jest kluczowe dla osiągnięcia dobrych wyników, co jednak może być trudne do uzyskania.\n",
    "\n",
    "\n",
    "### 4.2 Porównanie wyników\n",
    "\n",
    "Wyniki eksperymentów przeprowadzonych dla algorytmu MetaCost oraz KMeans przedstawiono w poniższych tabelach. Warto zauważyć, że MetaCost z metryką manhattan osiągnął najlepsze wyniki, a KMeans miał znacznie gorszą wydajność w detekcji outlierów w porównaniu do MetaCost.\n",
    "\n",
    "### Zbiór HTTP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "      model       metric  accuracy  positive_recall  negative_recall  \\\n0  metacost  mahalanobis  0.740794         0.599367         0.741347   \n1  metacost    euclidean  0.658134         0.605066         0.658341   \n2  metacost    cityblock  0.569373         0.995477         0.567706   \n3    kmeans    euclidean  0.566687         0.005427         0.568883   \n4    kmeans    manhattan  0.990925         0.014925         0.994742   \n5    kmeans  mahalanobis  0.567260         0.005427         0.569458   \n\n   positive_precision  negative_precision        f1  auc_score  \n0            0.025614            0.998417  0.019925        NaN  \n1            0.026622            0.997898  0.017355        NaN  \n2            0.008935            0.999969  0.017711        NaN  \n3            0.000049            0.993208  0.000098   0.538963  \n4            0.010982            0.996142  0.012653   0.538963  \n5            0.000049            0.993215  0.000098   0.539007  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>f1</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>metacost</td>\n      <td>mahalanobis</td>\n      <td>0.740794</td>\n      <td>0.599367</td>\n      <td>0.741347</td>\n      <td>0.025614</td>\n      <td>0.998417</td>\n      <td>0.019925</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>metacost</td>\n      <td>euclidean</td>\n      <td>0.658134</td>\n      <td>0.605066</td>\n      <td>0.658341</td>\n      <td>0.026622</td>\n      <td>0.997898</td>\n      <td>0.017355</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>metacost</td>\n      <td>cityblock</td>\n      <td>0.569373</td>\n      <td>0.995477</td>\n      <td>0.567706</td>\n      <td>0.008935</td>\n      <td>0.999969</td>\n      <td>0.017711</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kmeans</td>\n      <td>euclidean</td>\n      <td>0.566687</td>\n      <td>0.005427</td>\n      <td>0.568883</td>\n      <td>0.000049</td>\n      <td>0.993208</td>\n      <td>0.000098</td>\n      <td>0.538963</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kmeans</td>\n      <td>manhattan</td>\n      <td>0.990925</td>\n      <td>0.014925</td>\n      <td>0.994742</td>\n      <td>0.010982</td>\n      <td>0.996142</td>\n      <td>0.012653</td>\n      <td>0.538963</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>kmeans</td>\n      <td>mahalanobis</td>\n      <td>0.567260</td>\n      <td>0.005427</td>\n      <td>0.569458</td>\n      <td>0.000049</td>\n      <td>0.993215</td>\n      <td>0.000098</td>\n      <td>0.539007</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_files('./results/', models_excluded=['dbscan', 'agglomerative', 'isolationforest', 'svm'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T02:04:42.777630Z",
     "start_time": "2024-06-16T02:04:42.761583Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dla zbioru Kmeans HTTP udąło się diametralnie  zwiekszyc wartość wykrywanych outlierów z 1-0.5% do prawie 100%(positive recall). Niestety wpływa to negatywnie na wykrywalność inlierów, więc udział przypadków Fałsz pozytywnych jest wysoki. Tylko 50% próbek niebędących anomaliamii w najlepszym przypadku została wykryta których jest przecież znacznie więcej.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "      model       metric  accuracy  positive_recall  negative_recall  \\\n0  metacost  mahalanobis  0.851531         0.970094         0.842399   \n1  metacost    euclidean  0.851543         0.970664         0.842368   \n2  metacost    cityblock  0.857625         0.957391         0.849941   \n3    kmeans    euclidean  0.974907         0.690117         0.996841   \n4    kmeans    manhattan  0.786851         0.017374         0.846115   \n5    kmeans  mahalanobis  0.996089         0.946169         0.999934   \n\n   positive_precision  negative_precision        f1  auc_score  \n0            0.321713            0.997274  0.483156        NaN  \n1            0.321730            0.997326  0.483265        NaN  \n2            0.329490            0.996154  0.490254        NaN  \n3            0.943903            0.976617  0.797302   0.373327  \n4            0.008621            0.917898  0.011524   0.845926  \n5            0.999098            0.995871  0.971913   0.429757  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>f1</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>metacost</td>\n      <td>mahalanobis</td>\n      <td>0.851531</td>\n      <td>0.970094</td>\n      <td>0.842399</td>\n      <td>0.321713</td>\n      <td>0.997274</td>\n      <td>0.483156</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>metacost</td>\n      <td>euclidean</td>\n      <td>0.851543</td>\n      <td>0.970664</td>\n      <td>0.842368</td>\n      <td>0.321730</td>\n      <td>0.997326</td>\n      <td>0.483265</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>metacost</td>\n      <td>cityblock</td>\n      <td>0.857625</td>\n      <td>0.957391</td>\n      <td>0.849941</td>\n      <td>0.329490</td>\n      <td>0.996154</td>\n      <td>0.490254</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kmeans</td>\n      <td>euclidean</td>\n      <td>0.974907</td>\n      <td>0.690117</td>\n      <td>0.996841</td>\n      <td>0.943903</td>\n      <td>0.976617</td>\n      <td>0.797302</td>\n      <td>0.373327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kmeans</td>\n      <td>manhattan</td>\n      <td>0.786851</td>\n      <td>0.017374</td>\n      <td>0.846115</td>\n      <td>0.008621</td>\n      <td>0.917898</td>\n      <td>0.011524</td>\n      <td>0.845926</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>kmeans</td>\n      <td>mahalanobis</td>\n      <td>0.996089</td>\n      <td>0.946169</td>\n      <td>0.999934</td>\n      <td>0.999098</td>\n      <td>0.995871</td>\n      <td>0.971913</td>\n      <td>0.429757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_files('./results/', models_excluded=['dbscan', 'agglomerative', 'isolationforest', 'svm'], pdataset='shuttle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T00:56:52.284359Z",
     "start_time": "2024-06-16T00:56:52.271067Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sytuacja tutaj wygląda podobnie jak dla zbioru HTTP. Aczkowlwiek wyniki dla metacost dla metryki negative recall są znacznie lepsze niż dla zbioru HTTP. Jednak nadal mamy dużą ilość fałszywych pozytywów, widac to także po stosunkowo niskiej wartości F1 w porównaniu do poprzednio badanych algorytmów. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Podsumowanie\n",
    "\n",
    "W ramach projektu przeprowadzono eksperymenty z użyciem różnych algorytmów grupowania oraz klasyfikacji jednoklasowej w celu detekcji anomalii w zbiorach danych HTTP oraz Shuttle. Wyniki eksperymentów pokazały, że modele klasyfikacji jednoklasowej radzą sobie nieco lepiej w detekcji samych anomalii niż modele grupowania. Jednak jako klasyfikatory obu klas wypadały znacznie gorzej. Najbardziej miarodajnym zbiorem był sosunkowo trudny zbiór anomalii HTTP (dużo przykładów i mało anomalli). Jednak dla obydwu zbiorów najlepszym wyborem pod względem wykrywania anomalii i małej ilości False positive jest DBSCAN(metryka euklidesowa lub manhattan). Ciekawym modelem jeśli chodzi o klasyfikację jednoklasową jest Isolation Forest, byc może po zasotowaniu tuningu hiperparametrów mógłby osiągnąc lepsze wyniki niż obecnie.\n",
    "\n",
    "Jeśli chodzi o algorytm Meta Cost  to badania pokazały ze jest wstanie zmienić propocję wykrywanych klas w zależności od macierzy kosztów. Jednakże w naszym przypadku nie udało się uzyskać zadowalających wyniików, poniewąż jedyny algorytm jakie mozna było wykorzystac to KMeans  ktry miał najgorsze wyniki w porównaniu do pozostałych algorytmów grupowania."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
