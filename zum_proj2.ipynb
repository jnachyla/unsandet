{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ZUM</center>\n",
    "# <center> Projekt -- dokumentacja końcowa </center>\n",
    "\n",
    "## <center> Jan Budziński -- 310609 </center>\n",
    "## <center> Jarosław Nachyła -- nr_indeksu </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementacja\n",
    "\n",
    "### 2.1. Nienadzorowana detekcja anomalii\n",
    "\n",
    "W ramach projektu zaimplementowano klasę <i>AnomalyDetector</i>, będącą opakowaniem na algorytmy grupowania KMeans, DBSCAN oraz AgglomerativeClustering, jak również na miary niepodobieństwa euklidesową, Mahalanobisa i Manhattan. Celem tejże klasy jest stworzenie łatwego w obsłudze środowiska testowego, które w miarę możliwości (niektóre algorytmy różnią się wejściami) będzie jednorodne w użyciu dla każdego z porównywanych algorytmów i miar.\n",
    "Klasa ta zawiera następujące metody:\n",
    "\n",
    "- fit -- dopasowuje model do danych wejściowych,\n",
    "- fit_predict -- wykonuje trening modelu i jednocześnie przewidująca klasy i określająca dystanse od centrów klastrów dla danych wejściowych,\n",
    "- transform_distances -- określa, czy dane wejściowe są anomaliami na podstawie dystansu otrzymanego z wybranej miary niepodobieństwa,\n",
    "- transform_labels -- dla liczby klastrów większych niż 2, metoda ta zmienia przypisanie do wszystkich klastrów poza najliczniejszym w anomalię.\n",
    "\n",
    "\n",
    "Dzięki tym metodom użytkownik jest w stanie w łatwy sposób testować różne modele i miary niepodobieństwa, zmieniając wyłącznie jeden parametr w kodzie.\n",
    "\n",
    "Kod implementujący tę klasę jest w pliku anomaly_detector.py.\n",
    "\n",
    "Ponadto utworzono klasę <i>AnomalyDetectorEvaluator</i> zawierającą metody obliczające metryki potrzebne do ewaluacji wytrenowanych modeli.\n",
    "\n",
    "Testowane metryki to:\n",
    "\n",
    "- dokładność (accuracy)\n",
    "- precyzja (precision)\n",
    "- czułość (recall)\n",
    "- pole pod wykresem PRC\n",
    "\n",
    "Wszystkie te metryki zostały dokładniej opisane w dokumentacji wstępnej. Jednakże, z uwagi na fakt, iż dane z założenia są wysoce niezbalansowane (jako że są to dane anomalii, to wejścia o pozytywnej klasie stanowią poniżej 1% wszystkich) uznano, że zwykła dokładność może niewiele powiedzieć, jako że przypisanie wszystkim danym klasy negatywnej pozwala osiągnąć powyżej 99% poprawnych predykcji. W tym celu dodano metrykę dokładności wykrywania outlierów, która testuje, ile spośród prawdziwych outlierów zostało poprawnie zidentyfikowanych. \n",
    "\n",
    "Kod z klasą AnomalyDetectorEvaluator znajduje się w pliku metrics.py.\n",
    "\n",
    "### 2.2. Jednoklasowy klasyfikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Eksperymenty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_metrics_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def process_files(directory):\n",
    "    results = []\n",
    "    \n",
    "    # Przeglądanie wszystkich plików w katalogu\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # Parsing nazwy pliku\n",
    "            parts = file_name.split('_')\n",
    "            model = parts[0]\n",
    "            dataset = parts[1]\n",
    "            metric = parts[2].split('.')[0]\n",
    "\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            metrics_data = load_metrics_from_json(file_path)\n",
    "\n",
    "            for entry in metrics_data:\n",
    "                avg_metrics = entry['avg_metrics']\n",
    "                result = {\n",
    "                    'model': model,\n",
    "                    'dataset': dataset,\n",
    "                    'metric': metric,\n",
    "                    'accuracy': avg_metrics.get('accuracy'),\n",
    "                    'precision': avg_metrics.get('precision'),\n",
    "                    'recall': avg_metrics.get('recall'),\n",
    "                    'f1': avg_metrics.get('f1'),\n",
    "                    'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                    'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                    'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                    'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                    'auc_score': avg_metrics.get('auc_pr')\n",
    "                }\n",
    "                results.append(result)\n",
    "    \n",
    "    # Tworzenie DataFrame z wynikami\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Porównanie modeli grupowania\n",
    "\n",
    "W ramach pierwszego eksperymentu wykonano testy porównawcze iloczynu kartezjańskiego 3 wybranych modeli, 3 miar niepodobieństwa i 2 zbiorów danych, czyli łącznie 18 pojedynczych testów.\n",
    "\n",
    "Podczas przeprowadzania eksperymentu wystąpiły pewne problemy. Mianowicie, algorytm AgglomerativeClustering cechuje się wysokimi złożonościami: złożoność obliczeniowa to $O(n^2)$, a czasowa to $O(n^3)$. Z tego względu trening na całych zbiorach danych, a w szczególności na zbiorze HTTP był niemożliwy. W związku z tym zastosowano subsampling.\n",
    "\n",
    "Wyniki testów przedstawione są w poniższych tabelach.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "              model dataset       metric  accuracy  precision    recall  \\\n0   isolationforest    http          N/A  0.907282   0.729462  1.000000   \n1            dbscan    http    euclidean  0.993616   0.854988  1.000000   \n2            dbscan    http    manhattan  0.993616   0.854988  1.000000   \n3               svm    http          N/A  0.623021   0.398738  1.000000   \n4          metacost    http  mahalanobis  0.580502   0.007331  0.794211   \n5          metacost    http    euclidean  0.747444   0.036003  0.017910   \n6          metacost    http    cityblock  0.570846   0.008953  0.995025   \n7            kmeans    http    euclidean  0.565949   0.008857  0.995477   \n8            kmeans    http    cityblock  0.999942   0.988779  0.996382   \n9            kmeans    http  mahalanobis  0.990934   0.011000  0.014925   \n10    agglomerative    http    euclidean  0.994651   0.933531  0.997286   \n11    agglomerative    http    manhattan  0.994651   0.933531  0.997286   \n12    agglomerative    http  mahalanobis  0.994651   0.933531  0.997286   \n\n          f1  positive_recall  negative_recall  positive_precision  \\\n0   0.843571         1.000000         0.876376            0.729462   \n1   0.921826         1.000000         0.993366            0.854988   \n2   0.921826         1.000000         0.993366            0.854988   \n3   0.570139         1.000000         0.497362            0.398738   \n4   0.014528         0.794211         0.579666            0.007331   \n5   0.012120         0.017910         0.750297            0.036003   \n6   0.017747         0.995025         0.569187            0.008953   \n7   0.017557         0.995477         0.564269            0.008857   \n8   0.992566         0.996382         0.999956            0.988779   \n9   0.012666         0.014925         0.994751            0.011000   \n10  0.964356         0.997286         0.994445            0.933531   \n11  0.964356         0.997286         0.994445            0.933531   \n12  0.964356         0.997286         0.994445            0.933531   \n\n    negative_precision  auc_score  \n0             1.000000        NaN  \n1             1.000000   0.035111  \n2             1.000000   0.035111  \n3             1.000000        NaN  \n4             0.998617        NaN  \n5             0.994549        NaN  \n6             0.999966        NaN  \n7             0.999969   0.538962  \n8             0.999986   0.015064  \n9             0.996142   0.538960  \n10            0.999787   0.061553  \n11            0.999787   0.063167  \n12            0.999787   0.062629  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>isolationforest</td>\n      <td>http</td>\n      <td>N/A</td>\n      <td>0.907282</td>\n      <td>0.729462</td>\n      <td>1.000000</td>\n      <td>0.843571</td>\n      <td>1.000000</td>\n      <td>0.876376</td>\n      <td>0.729462</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dbscan</td>\n      <td>http</td>\n      <td>euclidean</td>\n      <td>0.993616</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.921826</td>\n      <td>1.000000</td>\n      <td>0.993366</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.035111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dbscan</td>\n      <td>http</td>\n      <td>manhattan</td>\n      <td>0.993616</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.921826</td>\n      <td>1.000000</td>\n      <td>0.993366</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.035111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>svm</td>\n      <td>http</td>\n      <td>N/A</td>\n      <td>0.623021</td>\n      <td>0.398738</td>\n      <td>1.000000</td>\n      <td>0.570139</td>\n      <td>1.000000</td>\n      <td>0.497362</td>\n      <td>0.398738</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>metacost</td>\n      <td>http</td>\n      <td>mahalanobis</td>\n      <td>0.580502</td>\n      <td>0.007331</td>\n      <td>0.794211</td>\n      <td>0.014528</td>\n      <td>0.794211</td>\n      <td>0.579666</td>\n      <td>0.007331</td>\n      <td>0.998617</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>metacost</td>\n      <td>http</td>\n      <td>euclidean</td>\n      <td>0.747444</td>\n      <td>0.036003</td>\n      <td>0.017910</td>\n      <td>0.012120</td>\n      <td>0.017910</td>\n      <td>0.750297</td>\n      <td>0.036003</td>\n      <td>0.994549</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>metacost</td>\n      <td>http</td>\n      <td>cityblock</td>\n      <td>0.570846</td>\n      <td>0.008953</td>\n      <td>0.995025</td>\n      <td>0.017747</td>\n      <td>0.995025</td>\n      <td>0.569187</td>\n      <td>0.008953</td>\n      <td>0.999966</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>kmeans</td>\n      <td>http</td>\n      <td>euclidean</td>\n      <td>0.565949</td>\n      <td>0.008857</td>\n      <td>0.995477</td>\n      <td>0.017557</td>\n      <td>0.995477</td>\n      <td>0.564269</td>\n      <td>0.008857</td>\n      <td>0.999969</td>\n      <td>0.538962</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>kmeans</td>\n      <td>http</td>\n      <td>cityblock</td>\n      <td>0.999942</td>\n      <td>0.988779</td>\n      <td>0.996382</td>\n      <td>0.992566</td>\n      <td>0.996382</td>\n      <td>0.999956</td>\n      <td>0.988779</td>\n      <td>0.999986</td>\n      <td>0.015064</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>kmeans</td>\n      <td>http</td>\n      <td>mahalanobis</td>\n      <td>0.990934</td>\n      <td>0.011000</td>\n      <td>0.014925</td>\n      <td>0.012666</td>\n      <td>0.014925</td>\n      <td>0.994751</td>\n      <td>0.011000</td>\n      <td>0.996142</td>\n      <td>0.538960</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>agglomerative</td>\n      <td>http</td>\n      <td>euclidean</td>\n      <td>0.994651</td>\n      <td>0.933531</td>\n      <td>0.997286</td>\n      <td>0.964356</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.061553</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>agglomerative</td>\n      <td>http</td>\n      <td>manhattan</td>\n      <td>0.994651</td>\n      <td>0.933531</td>\n      <td>0.997286</td>\n      <td>0.964356</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.063167</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>agglomerative</td>\n      <td>http</td>\n      <td>mahalanobis</td>\n      <td>0.994651</td>\n      <td>0.933531</td>\n      <td>0.997286</td>\n      <td>0.964356</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.062629</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_metrics_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "def process_files(directory, pdataset = \"http\"):\n",
    "    results = []\n",
    "\n",
    "    # Przeglądanie wszystkich plików w katalogu\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # Parsing nazwy pliku\n",
    "            parts = file_name.split('_')\n",
    "            model = parts[0]\n",
    "            dataset = parts[1]\n",
    "\n",
    "            if dataset != pdataset:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            metrics_data = load_metrics_from_json(file_path)\n",
    "\n",
    "\n",
    "\n",
    "            if isinstance(metrics_data, dict):  # Dla isolation forest i svm\n",
    "                metric = \"N/A\"\n",
    "                avg_metrics = metrics_data['avg_metrics']\n",
    "                result = {\n",
    "                    'model': model,\n",
    "                    'dataset': dataset,\n",
    "                    'metric': metric,\n",
    "                    'accuracy': avg_metrics.get('accuracy'),\n",
    "                    'precision': avg_metrics.get('precision'),\n",
    "                    'recall': avg_metrics.get('recall'),\n",
    "                    'f1': avg_metrics.get('f1'),\n",
    "                    'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                    'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                    'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                    'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                    'auc_score': avg_metrics.get('auc_pr')\n",
    "                }\n",
    "                results.append(result)\n",
    "            else:  # Dla pozostałych modeli\n",
    "                for entry in metrics_data:\n",
    "                    metric = entry['metric']\n",
    "                    avg_metrics = entry['avg_metrics']\n",
    "                    result = {\n",
    "                        'model': model,\n",
    "                        'dataset': dataset,\n",
    "                        'metric': metric,\n",
    "                        'accuracy': avg_metrics.get('accuracy'),\n",
    "                        'precision': avg_metrics.get('precision'),\n",
    "                        'recall': avg_metrics.get('recall'),\n",
    "                        'f1': avg_metrics.get('f1'),\n",
    "                        'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                        'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                        'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                        'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                        'auc_score': avg_metrics.get('auc_pr')\n",
    "                    }\n",
    "                    results.append(result)\n",
    "\n",
    "    # Tworzenie DataFrame z wynikami\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "process_files('./')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T00:06:20.761844Z",
     "start_time": "2024-06-16T00:06:20.740062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             model  dataset       metric  accuracy  precision    recall  \\\n0           dbscan  shuttle    euclidean  0.993971   0.957326  0.958416   \n1           dbscan  shuttle    manhattan  0.995376   0.954596  0.982056   \n2              svm  shuttle          N/A  0.635503   0.406425  0.994588   \n3    agglomerative  shuttle    euclidean  0.995988   0.999096  0.944745   \n4    agglomerative  shuttle    manhattan  0.995988   0.999096  0.944745   \n5    agglomerative  shuttle  mahalanobis  0.995988   0.999096  0.944745   \n6           kmeans  shuttle    euclidean  0.974907   0.943903  0.690117   \n7           kmeans  shuttle    manhattan  0.786851   0.008621  0.017374   \n8           kmeans  shuttle  mahalanobis  0.996089   0.999098  0.946169   \n9  isolationforest  shuttle          N/A  0.888208   0.693906  0.989177   \n\n         f1  positive_recall  negative_recall  positive_precision  \\\n0  0.957871         0.958416         0.996710            0.957326   \n1  0.968131         0.982056         0.996402            0.954596   \n2  0.577047         0.994588         0.515807            0.406425   \n3  0.971161         0.944745         0.999934            0.999096   \n4  0.971161         0.944745         0.999934            0.999096   \n5  0.971161         0.944745         0.999934            0.999096   \n6  0.797302         0.690117         0.996841            0.943903   \n7  0.011524         0.017374         0.846115            0.008621   \n8  0.971913         0.946169         0.999934            0.999098   \n9  0.815641         0.989177         0.854552            0.693906   \n\n   negative_precision  auc_score  \n0            0.996797   0.215972  \n1            0.998615   0.216555  \n2            0.996515        NaN  \n3            0.995762   0.435803  \n4            0.995762   0.530860  \n5            0.995762   0.429757  \n6            0.976617   0.373327  \n7            0.917898   0.845926  \n8            0.995871   0.429757  \n9            0.995796        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dbscan</td>\n      <td>shuttle</td>\n      <td>euclidean</td>\n      <td>0.993971</td>\n      <td>0.957326</td>\n      <td>0.958416</td>\n      <td>0.957871</td>\n      <td>0.958416</td>\n      <td>0.996710</td>\n      <td>0.957326</td>\n      <td>0.996797</td>\n      <td>0.215972</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dbscan</td>\n      <td>shuttle</td>\n      <td>manhattan</td>\n      <td>0.995376</td>\n      <td>0.954596</td>\n      <td>0.982056</td>\n      <td>0.968131</td>\n      <td>0.982056</td>\n      <td>0.996402</td>\n      <td>0.954596</td>\n      <td>0.998615</td>\n      <td>0.216555</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>svm</td>\n      <td>shuttle</td>\n      <td>N/A</td>\n      <td>0.635503</td>\n      <td>0.406425</td>\n      <td>0.994588</td>\n      <td>0.577047</td>\n      <td>0.994588</td>\n      <td>0.515807</td>\n      <td>0.406425</td>\n      <td>0.996515</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>agglomerative</td>\n      <td>shuttle</td>\n      <td>euclidean</td>\n      <td>0.995988</td>\n      <td>0.999096</td>\n      <td>0.944745</td>\n      <td>0.971161</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.435803</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>agglomerative</td>\n      <td>shuttle</td>\n      <td>manhattan</td>\n      <td>0.995988</td>\n      <td>0.999096</td>\n      <td>0.944745</td>\n      <td>0.971161</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.530860</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>agglomerative</td>\n      <td>shuttle</td>\n      <td>mahalanobis</td>\n      <td>0.995988</td>\n      <td>0.999096</td>\n      <td>0.944745</td>\n      <td>0.971161</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.429757</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>kmeans</td>\n      <td>shuttle</td>\n      <td>euclidean</td>\n      <td>0.974907</td>\n      <td>0.943903</td>\n      <td>0.690117</td>\n      <td>0.797302</td>\n      <td>0.690117</td>\n      <td>0.996841</td>\n      <td>0.943903</td>\n      <td>0.976617</td>\n      <td>0.373327</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>kmeans</td>\n      <td>shuttle</td>\n      <td>manhattan</td>\n      <td>0.786851</td>\n      <td>0.008621</td>\n      <td>0.017374</td>\n      <td>0.011524</td>\n      <td>0.017374</td>\n      <td>0.846115</td>\n      <td>0.008621</td>\n      <td>0.917898</td>\n      <td>0.845926</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>kmeans</td>\n      <td>shuttle</td>\n      <td>mahalanobis</td>\n      <td>0.996089</td>\n      <td>0.999098</td>\n      <td>0.946169</td>\n      <td>0.971913</td>\n      <td>0.946169</td>\n      <td>0.999934</td>\n      <td>0.999098</td>\n      <td>0.995871</td>\n      <td>0.429757</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>isolationforest</td>\n      <td>shuttle</td>\n      <td>N/A</td>\n      <td>0.888208</td>\n      <td>0.693906</td>\n      <td>0.989177</td>\n      <td>0.815641</td>\n      <td>0.989177</td>\n      <td>0.854552</td>\n      <td>0.693906</td>\n      <td>0.995796</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_files('./', pdataset=\"shuttle\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T00:06:31.696383Z",
     "start_time": "2024-06-16T00:06:31.679860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
