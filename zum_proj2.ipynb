{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ZUM</center>\n",
    "# <center> Projekt -- dokumentacja końcowa </center>\n",
    "\n",
    "## <center> Jan Budziński -- 310609 </center>\n",
    "## <center> Jarosław Nachyła -- nr_indeksu </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementacja\n",
    "\n",
    "### 2.1. Nienadzorowana detekcja anomalii\n",
    "\n",
    "W ramach projektu zaimplementowano klasę <i>AnomalyDetector</i>, będącą opakowaniem na algorytmy grupowania KMeans, DBSCAN oraz AgglomerativeClustering, jak również na miary niepodobieństwa euklidesową, Mahalanobisa i Manhattan. Celem tejże klasy jest stworzenie łatwego w obsłudze środowiska testowego, które w miarę możliwości (niektóre algorytmy różnią się wejściami) będzie jednorodne w użyciu dla każdego z porównywanych algorytmów i miar.\n",
    "Klasa ta zawiera następujące metody:\n",
    "\n",
    "- fit -- dopasowuje model do danych wejściowych,\n",
    "- fit_predict -- wykonuje trening modelu i jednocześnie przewidująca klasy i określająca dystanse od centrów klastrów dla danych wejściowych,\n",
    "- transform_distances -- określa, czy dane wejściowe są anomaliami na podstawie dystansu otrzymanego z wybranej miary niepodobieństwa,\n",
    "- transform_labels -- dla liczby klastrów większych niż 2, metoda ta zmienia przypisanie do wszystkich klastrów poza najliczniejszym w anomalię.\n",
    "\n",
    "\n",
    "Dzięki tym metodom użytkownik jest w stanie w łatwy sposób testować różne modele i miary niepodobieństwa, zmieniając wyłącznie jeden parametr w kodzie.\n",
    "\n",
    "Kod implementujący tę klasę jest w pliku anomaly_detector.py.\n",
    "\n",
    "Ponadto utworzono klasę <i>AnomalyDetectorEvaluator</i> zawierającą metody obliczające metryki potrzebne do ewaluacji wytrenowanych modeli.\n",
    "\n",
    "Testowane metryki to:\n",
    "\n",
    "- dokładność (accuracy)\n",
    "- precyzja (precision)\n",
    "- czułość (recall)\n",
    "- pole pod wykresem PRC\n",
    "\n",
    "Wszystkie te metryki zostały dokładniej opisane w dokumentacji wstępnej. Jednakże, z uwagi na fakt, iż dane z założenia są wysoce niezbalansowane (jako że są to dane anomalii, to wejścia o pozytywnej klasie stanowią poniżej 1% wszystkich) uznano, że zwykła dokładność może niewiele powiedzieć, jako że przypisanie wszystkim danym klasy negatywnej pozwala osiągnąć powyżej 99% poprawnych predykcji. W tym celu dodano metrykę dokładności wykrywania outlierów, która testuje, ile spośród prawdziwych outlierów zostało poprawnie zidentyfikowanych. \n",
    "\n",
    "Kod z klasą AnomalyDetectorEvaluator znajduje się w pliku metrics.py.\n",
    "\n",
    "### 2.2. Jednoklasowy klasyfikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Eksperymenty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_metrics_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def process_files(directory):\n",
    "    results = []\n",
    "    \n",
    "    # Przeglądanie wszystkich plików w katalogu\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # Parsing nazwy pliku\n",
    "            parts = file_name.split('_')\n",
    "            model = parts[0]\n",
    "            dataset = parts[1]\n",
    "            metric = parts[2].split('.')[0]\n",
    "\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            metrics_data = load_metrics_from_json(file_path)\n",
    "\n",
    "            for entry in metrics_data:\n",
    "                avg_metrics = entry['avg_metrics']\n",
    "                result = {\n",
    "                    'model': model,\n",
    "                    'dataset': dataset,\n",
    "                    'metric': metric,\n",
    "                    'accuracy': avg_metrics.get('accuracy'),\n",
    "                    'precision': avg_metrics.get('precision'),\n",
    "                    'recall': avg_metrics.get('recall'),\n",
    "                    'f1': avg_metrics.get('f1'),\n",
    "                    'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                    'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                    'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                    'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                    'auc_score': avg_metrics.get('auc_pr')\n",
    "                }\n",
    "                results.append(result)\n",
    "    \n",
    "    # Tworzenie DataFrame z wynikami\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Porównanie modeli grupowania\n",
    "\n",
    "W ramach pierwszego eksperymentu wykonano testy porównawcze iloczynu kartezjańskiego 3 wybranych modeli, 3 miar niepodobieństwa i 2 zbiorów danych, czyli łącznie 18 pojedynczych testów.\n",
    "\n",
    "Podczas przeprowadzania eksperymentu wystąpiły pewne problemy. Mianowicie, algorytm AgglomerativeClustering cechuje się wysokimi złożonościami: złożoność obliczeniowa to $O(n^2)$, a czasowa to $O(n^3)$. Z tego względu trening na całych zbiorach danych, a w szczególności na zbiorze HTTP był niemożliwy. W związku z tym zastosowano subsampling.\n",
    "\n",
    "Wyniki testów przedstawione są w poniższych tabelach.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "              model dataset   metric  accuracy  precision    recall        f1  \\\n0   isolationforest    http      N/A  0.907282   0.729462  1.000000  0.843571   \n1            dbscan    http  results  0.993616   0.854988  1.000000  0.921826   \n2            dbscan    http  results  0.993616   0.854988  1.000000  0.921826   \n3               svm    http  results  0.623021   0.398738  1.000000  0.570139   \n4          metacost    http  results  0.580502   0.007331  0.794211  0.014528   \n5          metacost    http  results  0.747444   0.036003  0.017910  0.012120   \n6          metacost    http  results  0.570846   0.008953  0.995025  0.017747   \n7            kmeans    http  results  0.565949   0.008857  0.995477  0.017557   \n8            kmeans    http  results  0.999942   0.988779  0.996382  0.992566   \n9            kmeans    http  results  0.990934   0.011000  0.014925  0.012666   \n10    agglomerative    http  results  0.994651   0.933531  0.997286  0.964356   \n11    agglomerative    http  results  0.994651   0.933531  0.997286  0.964356   \n12    agglomerative    http  results  0.994651   0.933531  0.997286  0.964356   \n\n    positive_recall  negative_recall  positive_precision  negative_precision  \\\n0          1.000000         0.876376            0.729462            1.000000   \n1          1.000000         0.993366            0.854988            1.000000   \n2          1.000000         0.993366            0.854988            1.000000   \n3          1.000000         0.497362            0.398738            1.000000   \n4          0.794211         0.579666            0.007331            0.998617   \n5          0.017910         0.750297            0.036003            0.994549   \n6          0.995025         0.569187            0.008953            0.999966   \n7          0.995477         0.564269            0.008857            0.999969   \n8          0.996382         0.999956            0.988779            0.999986   \n9          0.014925         0.994751            0.011000            0.996142   \n10         0.997286         0.994445            0.933531            0.999787   \n11         0.997286         0.994445            0.933531            0.999787   \n12         0.997286         0.994445            0.933531            0.999787   \n\n    auc_score  \n0         NaN  \n1    0.035111  \n2    0.035111  \n3         NaN  \n4         NaN  \n5         NaN  \n6         NaN  \n7    0.538962  \n8    0.015064  \n9    0.538960  \n10   0.061553  \n11   0.063167  \n12   0.062629  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>isolationforest</td>\n      <td>http</td>\n      <td>N/A</td>\n      <td>0.907282</td>\n      <td>0.729462</td>\n      <td>1.000000</td>\n      <td>0.843571</td>\n      <td>1.000000</td>\n      <td>0.876376</td>\n      <td>0.729462</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dbscan</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.993616</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.921826</td>\n      <td>1.000000</td>\n      <td>0.993366</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.035111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dbscan</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.993616</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.921826</td>\n      <td>1.000000</td>\n      <td>0.993366</td>\n      <td>0.854988</td>\n      <td>1.000000</td>\n      <td>0.035111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>svm</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.623021</td>\n      <td>0.398738</td>\n      <td>1.000000</td>\n      <td>0.570139</td>\n      <td>1.000000</td>\n      <td>0.497362</td>\n      <td>0.398738</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>metacost</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.580502</td>\n      <td>0.007331</td>\n      <td>0.794211</td>\n      <td>0.014528</td>\n      <td>0.794211</td>\n      <td>0.579666</td>\n      <td>0.007331</td>\n      <td>0.998617</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>metacost</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.747444</td>\n      <td>0.036003</td>\n      <td>0.017910</td>\n      <td>0.012120</td>\n      <td>0.017910</td>\n      <td>0.750297</td>\n      <td>0.036003</td>\n      <td>0.994549</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>metacost</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.570846</td>\n      <td>0.008953</td>\n      <td>0.995025</td>\n      <td>0.017747</td>\n      <td>0.995025</td>\n      <td>0.569187</td>\n      <td>0.008953</td>\n      <td>0.999966</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>kmeans</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.565949</td>\n      <td>0.008857</td>\n      <td>0.995477</td>\n      <td>0.017557</td>\n      <td>0.995477</td>\n      <td>0.564269</td>\n      <td>0.008857</td>\n      <td>0.999969</td>\n      <td>0.538962</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>kmeans</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.999942</td>\n      <td>0.988779</td>\n      <td>0.996382</td>\n      <td>0.992566</td>\n      <td>0.996382</td>\n      <td>0.999956</td>\n      <td>0.988779</td>\n      <td>0.999986</td>\n      <td>0.015064</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>kmeans</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.990934</td>\n      <td>0.011000</td>\n      <td>0.014925</td>\n      <td>0.012666</td>\n      <td>0.014925</td>\n      <td>0.994751</td>\n      <td>0.011000</td>\n      <td>0.996142</td>\n      <td>0.538960</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>agglomerative</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.994651</td>\n      <td>0.933531</td>\n      <td>0.997286</td>\n      <td>0.964356</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.061553</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>agglomerative</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.994651</td>\n      <td>0.933531</td>\n      <td>0.997286</td>\n      <td>0.964356</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.063167</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>agglomerative</td>\n      <td>http</td>\n      <td>results</td>\n      <td>0.994651</td>\n      <td>0.933531</td>\n      <td>0.997286</td>\n      <td>0.964356</td>\n      <td>0.997286</td>\n      <td>0.994445</td>\n      <td>0.933531</td>\n      <td>0.999787</td>\n      <td>0.062629</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_metrics_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "def process_files(directory, pdataset = \"http\"):\n",
    "    results = []\n",
    "\n",
    "    # Przeglądanie wszystkich plików w katalogu\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # Parsing nazwy pliku\n",
    "            parts = file_name.split('_')\n",
    "            model = parts[0]\n",
    "            dataset = parts[1]\n",
    "\n",
    "            if dataset != pdataset:\n",
    "                continue\n",
    "\n",
    "            # Dla isolation forest i svm nie ma metryk odległości\n",
    "            if model in [\"isolationforest\", \"oneclasssvm\"]:\n",
    "                metric = \"N/A\"\n",
    "            else:\n",
    "                metric = parts[2].split('.')[0]\n",
    "\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            metrics_data = load_metrics_from_json(file_path)\n",
    "\n",
    "            if isinstance(metrics_data, dict):  # Dla isolation forest i svm\n",
    "                avg_metrics = metrics_data['avg_metrics']\n",
    "                result = {\n",
    "                    'model': model,\n",
    "                    'dataset': dataset,\n",
    "                    'metric': metric,\n",
    "                    'accuracy': avg_metrics.get('accuracy'),\n",
    "                    'precision': avg_metrics.get('precision'),\n",
    "                    'recall': avg_metrics.get('recall'),\n",
    "                    'f1': avg_metrics.get('f1'),\n",
    "                    'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                    'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                    'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                    'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                    'auc_score': avg_metrics.get('auc_pr')\n",
    "                }\n",
    "                results.append(result)\n",
    "            else:  # Dla pozostałych modeli\n",
    "                for entry in metrics_data:\n",
    "                    avg_metrics = entry['avg_metrics']\n",
    "                    result = {\n",
    "                        'model': model,\n",
    "                        'dataset': dataset,\n",
    "                        'metric': metric,\n",
    "                        'accuracy': avg_metrics.get('accuracy'),\n",
    "                        'precision': avg_metrics.get('precision'),\n",
    "                        'recall': avg_metrics.get('recall'),\n",
    "                        'f1': avg_metrics.get('f1'),\n",
    "                        'positive_recall': avg_metrics.get('positive_recall'),\n",
    "                        'negative_recall': avg_metrics.get('negative_recall'),\n",
    "                        'positive_precision': avg_metrics.get('positive_precision'),\n",
    "                        'negative_precision': avg_metrics.get('negative_precision'),\n",
    "                        'auc_score': avg_metrics.get('auc_pr')\n",
    "                    }\n",
    "                    results.append(result)\n",
    "\n",
    "    # Tworzenie DataFrame z wynikami\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    return df\n",
    "\n",
    "process_files('./')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T23:55:26.250020Z",
     "start_time": "2024-06-15T23:55:26.237660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "             model  dataset   metric  accuracy  precision    recall        f1  \\\n0           dbscan  shuttle  results  0.993971   0.957326  0.958416  0.957871   \n1           dbscan  shuttle  results  0.995376   0.954596  0.982056  0.968131   \n2              svm  shuttle  results  0.635503   0.406425  0.994588  0.577047   \n3    agglomerative  shuttle  results  0.995988   0.999096  0.944745  0.971161   \n4    agglomerative  shuttle  results  0.995988   0.999096  0.944745  0.971161   \n5    agglomerative  shuttle  results  0.995988   0.999096  0.944745  0.971161   \n6           kmeans  shuttle  results  0.974907   0.943903  0.690117  0.797302   \n7           kmeans  shuttle  results  0.786851   0.008621  0.017374  0.011524   \n8           kmeans  shuttle  results  0.996089   0.999098  0.946169  0.971913   \n9  isolationforest  shuttle      N/A  0.888208   0.693906  0.989177  0.815641   \n\n   positive_recall  negative_recall  positive_precision  negative_precision  \\\n0         0.958416         0.996710            0.957326            0.996797   \n1         0.982056         0.996402            0.954596            0.998615   \n2         0.994588         0.515807            0.406425            0.996515   \n3         0.944745         0.999934            0.999096            0.995762   \n4         0.944745         0.999934            0.999096            0.995762   \n5         0.944745         0.999934            0.999096            0.995762   \n6         0.690117         0.996841            0.943903            0.976617   \n7         0.017374         0.846115            0.008621            0.917898   \n8         0.946169         0.999934            0.999098            0.995871   \n9         0.989177         0.854552            0.693906            0.995796   \n\n   auc_score  \n0   0.215972  \n1   0.216555  \n2        NaN  \n3   0.435803  \n4   0.530860  \n5   0.429757  \n6   0.373327  \n7   0.845926  \n8   0.429757  \n9        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>metric</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>positive_recall</th>\n      <th>negative_recall</th>\n      <th>positive_precision</th>\n      <th>negative_precision</th>\n      <th>auc_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dbscan</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.993971</td>\n      <td>0.957326</td>\n      <td>0.958416</td>\n      <td>0.957871</td>\n      <td>0.958416</td>\n      <td>0.996710</td>\n      <td>0.957326</td>\n      <td>0.996797</td>\n      <td>0.215972</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dbscan</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.995376</td>\n      <td>0.954596</td>\n      <td>0.982056</td>\n      <td>0.968131</td>\n      <td>0.982056</td>\n      <td>0.996402</td>\n      <td>0.954596</td>\n      <td>0.998615</td>\n      <td>0.216555</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>svm</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.635503</td>\n      <td>0.406425</td>\n      <td>0.994588</td>\n      <td>0.577047</td>\n      <td>0.994588</td>\n      <td>0.515807</td>\n      <td>0.406425</td>\n      <td>0.996515</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>agglomerative</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.995988</td>\n      <td>0.999096</td>\n      <td>0.944745</td>\n      <td>0.971161</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.435803</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>agglomerative</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.995988</td>\n      <td>0.999096</td>\n      <td>0.944745</td>\n      <td>0.971161</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.530860</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>agglomerative</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.995988</td>\n      <td>0.999096</td>\n      <td>0.944745</td>\n      <td>0.971161</td>\n      <td>0.944745</td>\n      <td>0.999934</td>\n      <td>0.999096</td>\n      <td>0.995762</td>\n      <td>0.429757</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>kmeans</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.974907</td>\n      <td>0.943903</td>\n      <td>0.690117</td>\n      <td>0.797302</td>\n      <td>0.690117</td>\n      <td>0.996841</td>\n      <td>0.943903</td>\n      <td>0.976617</td>\n      <td>0.373327</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>kmeans</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.786851</td>\n      <td>0.008621</td>\n      <td>0.017374</td>\n      <td>0.011524</td>\n      <td>0.017374</td>\n      <td>0.846115</td>\n      <td>0.008621</td>\n      <td>0.917898</td>\n      <td>0.845926</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>kmeans</td>\n      <td>shuttle</td>\n      <td>results</td>\n      <td>0.996089</td>\n      <td>0.999098</td>\n      <td>0.946169</td>\n      <td>0.971913</td>\n      <td>0.946169</td>\n      <td>0.999934</td>\n      <td>0.999098</td>\n      <td>0.995871</td>\n      <td>0.429757</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>isolationforest</td>\n      <td>shuttle</td>\n      <td>N/A</td>\n      <td>0.888208</td>\n      <td>0.693906</td>\n      <td>0.989177</td>\n      <td>0.815641</td>\n      <td>0.989177</td>\n      <td>0.854552</td>\n      <td>0.693906</td>\n      <td>0.995796</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_files('./', pdataset=\"shuttle\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T23:55:57.123963Z",
     "start_time": "2024-06-15T23:55:57.110273Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
